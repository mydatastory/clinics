---
title: "Data Story Clinic"
output:
  tufte::tufte_handout:
    toc: no
    toc_depth: 1
    latex_engine: xelatex
  tufte::tufte_html:
    toc: yes
    toc_depth: 1
---

#\textcolor{blue}{Microbes and Babies}  

To hear the story your data wants to tell, you must sometimes use *set logic*.  In this story clinic, we're going to analyze an article dataset in which the authors compared the microbiomes of babies born vaginally to that of babies born via C-section.

Let's start by loading our microbiome dataset.

```{r}

df <-read.csv("genusMicrobiome.csv", header = TRUE, stringsAsFactors = FALSE)

```

Analyzing data from a *set logic* perspective requires one to slice a dataset up into a variety of subsets, each created by applying a unique set of logical conditions.  For example, let's start our analysis by creating a set of bacteria genera found in babies born vaginally but not via C-section.

```{r}

# Set s1 contains bacterial genera found in babies born naturally but not in 
# babies born via c-section.  The subset can be created one of two ways...

s1 <- subset(df, natural_newborn_avg > 0 & csect_newborn_avg <= 0)
s1 <- df[df$natural_newborn_avg > 0 & df$csect_newborn_avg <= 0,]

```

We can now create a barplot of this set.  In order to get the name of each genus to appear along the x-axis, we adjust the graph margins.

`r tufte::margin_note("Question 1 -- What graphical parameter is set in the code on the left?  Can you set the margins another way?  What parameter would you use to do that?")`

```{r fig.width = 5, fig.height = 5}

# Save the original set of parameters.

opar <- par(no.readonly = TRUE)

# Adjust the plot margins (bottom, left, top, right).

par(mai = c(1.25, .75, .25, .25))

barplot(s1$natural_newborn_avg, 
        names.arg = s1$genus,
        las       = 2,
        cex.names = .70,
        cex.axis  = .70, 
        col = 'lightblue')

# Reset the graph parameters to their original values.

par(opar)

```

Although the graph displays correctly, it isn't optimal because most of the bars are barely visible, due to the fact that the abundance is miniscule for most of the genera.  The problem is that the difference between the smallest and largest values is dramatic. The highest bars distort the graph, taking up most of the real-estate.  One way to fix this visual is to transform the data using either the `log()` or `log10()` functions.  The first function calculates the natural logarithm of a given number whereas the second calculates the base 10 logarithm. 

So how do logarithms work?  The code and comments below highlight how these functions work in R.

```{r}

# Let's create a tst variale and assign a value of 0.008812435 to it.  We can either assign 
# the value directly or retrieve it from the natural_newborn_avg column in row 20 of the s1 dataframe.

tst <- 0.008812435
tst <- s1[20, 'natural_newborn_avg'] 

# Calculate the natural log of this number.

log(tst)

# The natural log is a constant (2.178282).  The call `exp(1)` returns this value...

exp(1)

# The natural log of a number can be converted back to the original number by raising 2.178282 to
# the power of the value returned by the log() function.  If the natural log is negative, this indicates
# that the original number is less than 2.718282, as is the case here.

2.718282^-4.731591

# Now let's run the same process with the log10() function.

log10(tst)

# The base 10 log of a number can be converted back to the original number by raising 10 to
# the power of the value returned by the log10() function.  If the log10 value is negative, this
# indicates that the original number is less than 10, as is the case here.

10^-2.054904

# In both examples, rounding is evident as raising either 2.71 or 10 to the value returned by log()
# or log10() does not precisely equal the original number: 0.008812435.

```

The log functions perform non-linear transformations.  With a non-linear transformation, the relative spacing between numbers is not preserved.  In the example below, a set of five numbers are transformed into their log equivalents, each now being equidistant from its neighbor.

![Data Transformations (Log)](log_operation.gif)

Because of this unique propert, a log transformation is a useful operation, especially when we have one or more outliers that we'd like to *pull in*.  Indeed, it was those large numbers that distorted our original graph, making most of the bars practically invisible.  So let's see what happens when we create a barplot - like we did before - but pass a log transformation of the data to it.


```{r fig.width = 5, fig.height = 5}

# Save the original set of parameters.

opar <- par(no.readonly = TRUE)

# Adjust the plot margins (bottom, left, top, right).

par(mai = c(1.25, .75, .25, .25))

# Create the barplot like before but take the absolute value of the log for the y axis.  We use
# the absolute value because all of our logs are negative.

barplot(abs(log(s1$natural_newborn_avg)), 
        names.arg = s1$genus,
        las       = 2,
        cex.names = .70,
        cex.axis  = .70, 
        col = 'lightblue')

# Reset the graph parameters to their original values.

par(opar)

```

`r tufte::margin_note("Question 2 -- Can you think of other ways in which an unscrupulous person might spin a data story through distorted visuals?")`

At last, we can now see all of the bars!  Yet the relative (and large) difference between the smallest and largest values is no longer visual.  In this case, it seems that a picture is not worth a thousand words.  In fact, some might feel that this second graph is a bit deceptive.  So maybe the best solution is to display the data in a simple table and not graph it at all?  And that's precisely what we do in this next block of code.  


```{r}

knitr::kable(
  s1[, c(1:2)], caption = 'Genera in Natural Newborns not C-Sect Babies')
  
```

`r tufte::margin_note("Question 3 -- Using the str() function to view the variables in this dataframe, can you identify other subsets we might create for comparisons?")`

A *set logic* approach to data analysis involves doing what we just did.  First, you apply a logical condition to your data thereby creating a subset.  Then you apply another logical condition to create a different subset.  And finally, you compare the two.  Is one larger than the other?  Are there items in one subset not found in the other?

In this initial subset, we identified genera found in newborns born naturally but not in babies born via C-section.  Taking a *set logic* approach to our data, we may want to now compare this subset to another one that selects only those genera found in C-section babies but not in infants born naturally.  How would you create this subset?  And what did you learn from comparing the two?





